{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2020 Semester 1\n",
    "\n",
    "## Assignment 1: Naive Bayes Classifiers\n",
    "\n",
    "###### Submission deadline: 7 pm, Monday 20 Apr 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student Name(s):**    Shuyang Fan, Yiran Wang \n",
    "\n",
    "**Student ID(s):**     988301, 987751\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "Marking will be applied on the four functions that are defined in this notebook, and to your responses to the questions at the end of this notebook (Submitted in a separate PDF file).\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, DIAGRAMS AND IMAGES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).**\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find.\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from scipy.stats import mode "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "data_set =\"./datasets/bank.data\"\n",
    "\n",
    "# Read data from csv\n",
    "def read_data(fileName):\n",
    "    data = pd.read_csv(fileName, header=None)\n",
    "    # print(data.head(5))\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "def handle_missing_value(data):\n",
    "    # Make a copy of raw data\n",
    "    copy = data.copy()\n",
    "    # Drop rows contains question mark\n",
    "    copy = copy[(copy.astype(str) != '?').all(axis=1)]\n",
    "    # Extract label from data\n",
    "    label = copy.iloc[:,-1]\n",
    "    # Filling missing value with category mode for each column\n",
    "    for i in range(copy.shape[1] - 1):\n",
    "        copy.iloc[:,:i] = copy.iloc[:,:i].groupby(label).transform(lambda x: x.fillna(x.mode())) \n",
    "    # Print how many missing value have been handled \n",
    "    # print(data.isna().sum() - copy.isna().sum())\n",
    "    # return the modified copy\n",
    "    return copy\n",
    "\n",
    "def binning(data):\n",
    "    copy = data.copy()\n",
    "    \n",
    "    numeric_column = []\n",
    "    for column in range(copy.shape[1] - 1):\n",
    "        if (is_numeric_dtype(copy.iloc[:,column])):\n",
    "            numeric_column.append(column)\n",
    "        \n",
    "    discretizer(copy, numeric_column, [10 for i in range(len(numeric_column))])\n",
    "\n",
    "def discretizer(X, column_index, bin_size):\n",
    "    for index, column in enumerate(column_index):\n",
    "        X.iloc[:,column] = pd.cut(X.iloc[:,column], bin_size[index])\n",
    "\n",
    "def train_test_split(X, y, test_size=0.2):\n",
    "    X_total = X.shape[0]\n",
    "    assert(X_total == y.size)\n",
    "    arr_rand = np.random.rand(X.shape[0])\n",
    "    split = arr_rand < np.percentile(arr_rand, test_size*100)\n",
    "    X_train = X[split]\n",
    "    y_train = y[split]\n",
    "    X_test =  X[~split]\n",
    "    y_test = y[~split]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# This function should prepare the data by reading it from a file and converting it into a useful format for training and testing\n",
    "def preprocess(data):\n",
    "    handle_missing_value(data)\n",
    "    # print(data)\n",
    "    X = data.iloc[:,:-1]\n",
    "    y = data.iloc[:,-1]\n",
    "    \n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "dtype: int64\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "data = read_data(data_set)\n",
    "X,y = preprocess(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "{'no': 0.8801150188011502, 'yes': 0.11988498119884981}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 125
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "def get_prior(y_train):\n",
    "    train_inputs = y_train\n",
    "    labels, counts = np.unique(train_inputs, return_counts=True)\n",
    "    prior = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        prior[label] = float(counts[i])/len(train_inputs)\n",
    "    return prior      \n",
    "\n",
    "get_prior(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# This function should calculat prior probabilities and likelihoods from the training data and using\n",
    "# them to build a naive Bayes model\n",
    "\n",
    "def train(X_train, y_train):\n",
    "    grouped = X_train.groupby(y_train)\n",
    "    for label in np.unique(y_train):\n",
    "        print(grouped.get_group(label))\n",
    "    return\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "# train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# This function should predict classes for new items in a test dataset (for the purposes of this assignment, you\n",
    "# can re-use the training data as a test set)\n",
    "\n",
    "def predict():\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def random_baseline(X_train, y_train):\n",
    "    labels = np.unique(y_train)\n",
    "    y_baseline = [np.random.choice(labels) for i in range(len(y_train))]\n",
    "    return y_baseline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def zero_r_baseline(X_train, y_train):\n",
    "    label = mode(y_train)\n",
    "    return np.repeat(label, len(y_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.75\n",
      "1 4 0 0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def accuracy(y_predicted, y_truth):\n",
    "    assert(y_predicted.size==y_truth.size)\n",
    "    return np.sum(y_predicted == y_truth)/y_predicted.size\n",
    "\n",
    "print(accuracy(np.array([1,2,3,4]), np.array([1,2,3,5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def label_confusion_matrix(y_predicted, y_truth, label):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for index in range(y_predicted.size):\n",
    "        result =  y_predicted[index]\n",
    "        if (result==label):\n",
    "            if ((y_truth[index]) == label):\n",
    "                TP +=1\n",
    "            else:\n",
    "                FP +=1\n",
    "        else:\n",
    "            if ((y_truth[index]) == label):\n",
    "                FN += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "    return TP, TN, FP, FN\n",
    "                \n",
    "  \n",
    "(TP, TN, FP, FN) = label_confusion_matrix(np.array([1, 0, 0, 1, 2]), np.array([1, 0, 1, 0, 2]), 2)  \n",
    "print(TP, TN, FP, FN)    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This function should evaliate the prediction performance by comparing your modelâ€™s class outputs to ground\n",
    "# truth labels\n",
    "def evaluate():\n",
    "    return "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "\n",
    "\n",
    "If you are in a group of 1, you will respond to question (1), and **one** other of your choosing (two responses in total).\n",
    "\n",
    "If you are in a group of 2, you will respond to question (1) and question (2), and **two** others of your choosing (four responses in total). \n",
    "\n",
    "A response to a question should take about 100â€“250 words, and make reference to the data wherever possible.\n",
    "\n",
    "#### NOTE: you may develope codes or functions in respond to the question, but your formal answer should be added to a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "Try discretising the numeric attributes in these datasets and treating them as discrete variables in the naÂ¨Ä±ve Bayes classifier. You can use a discretisation method of your choice and group the numeric values into any number of levels (but around 3 to 5 levels would probably be a good starting point). Does discretizing the variables improve classification performance, compared to the Gaussian naÂ¨Ä±ve Bayes approach? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "Implement a baseline model (e.g., random or 0R) and compare the performance of the naÂ¨Ä±ve Bayes classifier to this baseline on multiple datasets. Discuss why the baseline performance varies across datasets, and to what extent the naÂ¨Ä±ve Bayes classifier improves on the baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "Since itâ€™s difficult to model the probabilities of ordinal data, ordinal attributes are often treated as either nominal variables or numeric variables. Compare these strategies on the ordinal datasets provided. Deterimine which approach gives higher classification accuracy and discuss why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a holdâ€“out or crossâ€“validation evaluation strategy (you should implement this yourself and do not simply call existing implementations from `scikit-learn`). How does your estimate of effectiveness change, compared to testing on the training data? Explain why. (The result might surprise you!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5\n",
    "Implement one of the advanced smoothing regimes (add-k, Good-Turing). Does changing the smoothing regime (or indeed, not smoothing at all) affect the effectiveness of the naÂ¨Ä±ve Bayes classifier? Explain why, or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6\n",
    "The Gaussian naÂ¨Ä±ve Bayes classifier assumes that numeric attributes come from a Gaussian distribution. Is this assumption always true for the numeric attributes in these datasets? Identify some cases where the Gaussian assumption is violated and describe any evidence (or lack thereof) that this has some effect on the NB classifierâ€™s predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}