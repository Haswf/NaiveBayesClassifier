{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2020 Semester 1\n",
    "\n",
    "## Assignment 1: Naive Bayes Classifiers\n",
    "\n",
    "###### Submission deadline: 7 pm, Monday 20 Apr 2020"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Student Name(s):**    Shuyang Fan, Yiran Wang \n",
    "\n",
    "**Student ID(s):**     988301, 987751\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "Marking will be applied on the four functions that are defined in this notebook, and to your responses to the questions at the end of this notebook (Submitted in a separate PDF file).\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, DIAGRAMS AND IMAGES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).**\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find.\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from scipy.stats import mode \n",
    "from collections import Counter, defaultdict\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "data_set =\"./datasets/adult.data\"\n",
    "\n",
    "# Read data from csv\n",
    "def read_data(fileName):\n",
    "    data = pd.read_csv(fileName, header=None)\n",
    "    # print(data.head(5))\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def handle_missing_value(data):\n",
    "    # Make a copy of raw data\n",
    "    copy = data.copy()\n",
    "    # Drop rows contains question mark\n",
    "    copy = copy[(copy.astype(str) != '?').all(axis=1)]\n",
    "    # Extract label from data\n",
    "    label = copy.iloc[:,-1]\n",
    "    # Filling missing value with category mode for each column\n",
    "    for i in range(copy.shape[1] - 1):\n",
    "        copy.iloc[:,:i] = copy.iloc[:,:i].groupby(label).transform(lambda x: x.fillna(x.mode())) \n",
    "    # Print how many missing value have been handled \n",
    "    # print(data.isna().sum() - copy.isna().sum())\n",
    "    # return the modified copy\n",
    "    return copy\n",
    "\n",
    "def binning(data):\n",
    "    copy = data.copy()\n",
    "    \n",
    "    numeric_column = []\n",
    "    for column in range(copy.shape[1] - 1):\n",
    "        if (is_numeric_dtype(copy.iloc[:,column])):\n",
    "            numeric_column.append(column)\n",
    "        \n",
    "        \n",
    "    discretizer(copy, numeric_column, [3 for i in range(len(numeric_column))])\n",
    "    #print(copy.head())\n",
    "    return copy\n",
    "    \n",
    "def discretizer(X, column_index, bin_size):\n",
    "    for index, column in enumerate(column_index):\n",
    "        X.iloc[:,column] = pd.cut(X.iloc[:,column], bin_size[index])\n",
    "\n",
    "def train_test_split(X, y, test_size=0.2):\n",
    "    X_total = X.shape[0]\n",
    "    assert(X_total == y.size)\n",
    "    arr_rand = np.random.rand(X.shape[0])\n",
    "    split = arr_rand < np.percentile(arr_rand, test_size*100)\n",
    "\n",
    "    \n",
    "    X_train = X[split]\n",
    "    y_train = y[split]\n",
    "    X_test =  X[~split]\n",
    "    y_test = y[~split]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# This function should prepare the data by reading it from a file and converting it into a useful format for training and testing\n",
    "def preprocess(data):\n",
    "    data = handle_missing_value(data)\n",
    "    # data = binning(data)\n",
    "    \n",
    "    # print(data)\n",
    "    X = data.iloc[:,:-1]\n",
    "    y = data.iloc[:,-1]\n",
    "\n",
    "    return X, y\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#Bayes calculate the product of prior and conditinoals,, take the max\n",
    "#then predict, throw the X-test into the model\n",
    "#then check the accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<=50K\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def find_key_with_max_value(dic):\n",
    "    max_value = -1e5\n",
    "    max_key = None\n",
    "    for key in dic:\n",
    "        if dic[key] > max_value:\n",
    "            max_key = key\n",
    "            max_value = dic[key]\n",
    "    return max_key\n",
    "print(find_key_with_max_value({'<=50K': -15.768737460661638, '>50K': -18.479883639470405}))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class BayesClassifier():\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.X_train = X_train.copy()\n",
    "        self.y_train = y_train.copy()\n",
    "        self.possible_labels = np.unique(self.y_train)\n",
    "        self.prior = self.get_prior(self.y_train)\n",
    "        self.categorical_prob = self.compute_categorical(self.X_train, self.y_train)\n",
    "        self.numeric_prob = self.compute_numeric(self.X_train, self.y_train)\n",
    "    \n",
    "    def get_prior(self, y_train):\n",
    "        train_inputs = y_train\n",
    "        #counts is a list that stores number of each label accordingly\n",
    "        labels, counts = np.unique(train_inputs, return_counts=True)\n",
    "        prior = {}\n",
    "        for i, label in enumerate(labels):\n",
    "            prior[label] = float(counts[i])/len(train_inputs)\n",
    "        return prior      \n",
    "    \n",
    "    def is_numeric_attribute(self, data, column_index):\n",
    "        return is_numeric_dtype(data.iloc[:,column_index])\n",
    "\n",
    "    def compute_categorical(self, X_train, y_train):\n",
    "        categorical_prob = defaultdict(lambda: defaultdict(dict))\n",
    "        # Sepeate training instances by label\n",
    "        grouped = X_train.groupby(y_train)\n",
    "\n",
    "        for label in self.possible_labels:\n",
    "            separated = grouped.get_group(label)\n",
    "            for column_index in range(X_train.shape[1]):\n",
    "                # Only process categorical attribute\n",
    "                if (self.is_numeric_attribute(X_train, column_index) == False):\n",
    "                    # Extract one attribute from group\n",
    "                    attribute = separated.iloc[:,column_index]\n",
    "                    total_rows = attribute.shape[0]\n",
    "                    # Find all possible values of this attribute\n",
    "                    possible_values = np.unique(X_train.iloc[:,column_index])\n",
    "                    # Call Counter to count the frequency of each value\n",
    "                    counts = Counter(attribute)\n",
    "                    for value in possible_values:\n",
    "                        if value in counts:\n",
    "                            categorical_prob[column_index][str(value)][label] = counts[value]/total_rows\n",
    "        return categorical_prob\n",
    "    \n",
    "    def compute_numeric(self, X_train, y_train):\n",
    "        numeric_prob = defaultdict(lambda: defaultdict(dict))\n",
    "        # Sepeate training instances by label\n",
    "        grouped = X_train.groupby(y_train)\n",
    "        \n",
    "        for label in self.possible_labels:\n",
    "            separated = grouped.get_group(label)\n",
    "            for column_index in range(X_train.shape[1]):\n",
    "                if self.is_numeric_attribute(X_train, column_index):\n",
    "                    # Extract the attribute from group\n",
    "                    attribute = separated.iloc[:,column_index]\n",
    "                    numeric_prob[column_index]['mean'][label] = attribute.mean()\n",
    "                    numeric_prob[column_index]['std'][label] = attribute.std()\n",
    "        return numeric_prob\n",
    "    \n",
    "    def guassian(self, value, mean, stdev):\n",
    "        exponent = math.exp(-(math.pow(value-mean,2)/(2*math.pow(stdev,2))))\n",
    "        return (1/(math.sqrt(2*math.pi)*stdev))*exponent\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X_test_copy = X_test.copy()\n",
    "        categorical_prob = self.categorical_prob\n",
    "        numeric_prob = self.numeric_prob \n",
    "        priors = self.prior\n",
    "        possible_labels = self.possible_labels\n",
    "        predicted_outputs = []\n",
    "    \n",
    "        row, column = X_test_copy.shape\n",
    "        for row_index in range(row):\n",
    "            probability = defaultdict(float)\n",
    "            \n",
    "            for label in possible_labels:\n",
    "                probability[label] = safe_log(priors[label])\n",
    "                \n",
    "            for column_index in range(column):\n",
    "                # Get the value of this attribute\n",
    "                value = X_test_copy.iloc[row_index, column_index]\n",
    "                # Get conditional probability\n",
    "                for label in possible_labels:\n",
    "                    if self.is_numeric_attribute(X_test_copy,column_index):\n",
    "                        conditional_probability = self.guassian(value, numeric_prob[column_index]['mean'][label], numeric_prob[column_index]['std'][label])\n",
    "                    else:\n",
    "                        if label not in categorical_prob[column_index][str(value)]:\n",
    "                            conditional_probability = 1e-9\n",
    "                        else:\n",
    "                            conditional_probability = categorical_prob[column_index][str(value)][label]\n",
    "                    probability[label] += safe_log(conditional_probability)\n",
    "            # The prediced outcome is the lebel with the highest probability\n",
    "            predicted_outputs.append(find_key_with_max_value(probability))\n",
    "        return predicted_outputs\n",
    "    \n",
    "data = read_data(data_set)\n",
    "X,y = preprocess(data)\n",
    "\n",
    "def safe_log(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    return math.log(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def accuracy(y_predicted, y_truth):\n",
    "    assert(y_predicted.size==y_truth.size)\n",
    "    return np.sum(y_predicted == y_truth)/y_predicted.size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.8275104645861826\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "bayes = BayesClassifier()\n",
    "bayes.train(X_train, y_train)\n",
    "result = bayes.predict(X_test)\n",
    "print(accuracy(np.array(result), y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def random_baseline(X_train, y_train):\n",
    "    labels = np.unique(y_train)\n",
    "    y_baseline = [np.random.choice(labels) for i in range(len(y_train))]\n",
    "    return y_baseline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def zero_r_baseline(X_train, y_train):\n",
    "    label = mode(y_train)\n",
    "    return np.repeat(label, len(y_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1 4 0 0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def label_confusion_matrix(y_predicted, y_truth, label):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for index in range(y_predicted.size):\n",
    "        result =  y_predicted[index]\n",
    "        if (result==label):\n",
    "            if ((y_truth[index]) == label):\n",
    "                TP +=1\n",
    "            else:\n",
    "                FP +=1\n",
    "        else:\n",
    "            if ((y_truth[index]) == label):\n",
    "                FN += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "    return TP, TN, FP, FN\n",
    "                \n",
    "  \n",
    "(TP, TN, FP, FN) = label_confusion_matrix(np.array([1, 0, 0, 1, 2]), np.array([1, 0, 1, 0, 2]), 2)  \n",
    "print(TP, TN, FP, FN)  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Questions \n",
    "\n",
    "\n",
    "If you are in a group of 1, you will respond to question (1), and **one** other of your choosing (two responses in total).\n",
    "\n",
    "If you are in a group of 2, you will respond to question (1) and question (2), and **two** others of your choosing (four responses in total). \n",
    "\n",
    "A response to a question should take about 100â€“250 words, and make reference to the data wherever possible.\n",
    "\n",
    "#### NOTE: you may develope codes or functions in respond to the question, but your formal answer should be added to a separate file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}